{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f351a19",
   "metadata": {},
   "source": [
    "9. Comparación del Mejor Modelo de SVM vs Otros Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b522cd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados de Comparación de Modelos (clasificación):\n",
      "\n",
      "                     Accuracy  Tiempo (segundos)\n",
      "Mejor SVM            0.829000           0.150000\n",
      "Random Forest        0.818493           0.164809\n",
      "Regresión logística  0.804795           0.350034\n",
      "Naive Bayes          0.787671           0.000000\n",
      "KNN                  0.773973           0.016087\n",
      "Árbol de decisión    0.760274           0.003843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jemil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv(\"../dataset/train.csv\")\n",
    "\n",
    "# Crear la variable categórica PriceCategory\n",
    "df['PriceCategory'] = pd.qcut(df['SalePrice'], q=3, labels=['Económica', 'Intermedia', 'Cara'])\n",
    "\n",
    "# Variables predictoras y variable respuesta\n",
    "predictors = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'YearBuilt', 'FullBath']\n",
    "X = df[predictors]\n",
    "y = df['PriceCategory']\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Diccionario para guardar resultados\n",
    "resultados = {}\n",
    "\n",
    "# Función para entrenar y evaluar modelos\n",
    "def evaluar_modelo(nombre_modelo, modelo):\n",
    "    inicio = time.time()\n",
    "    modelo.fit(X_train, y_train)\n",
    "    predicciones = modelo.predict(X_test)\n",
    "    fin = time.time()\n",
    "    acc = accuracy_score(y_test, predicciones)\n",
    "    tiempo = fin - inicio\n",
    "    resultados[nombre_modelo] = {'Accuracy': acc, 'Tiempo (segundos)': tiempo}\n",
    "\n",
    "# Modelos a probar\n",
    "modelos = {\n",
    "    \"Árbol de decisión\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Regresión logística\": LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluar cada modelo\n",
    "for nombre, modelo in modelos.items():\n",
    "    evaluar_modelo(nombre, modelo)\n",
    "\n",
    "\n",
    "resultados[\"Mejor SVM\"] = {'Accuracy': 0.829, 'Tiempo (segundos)': 0.15}  \n",
    "\n",
    "# Mostrar resultados en DataFrame ordenado\n",
    "df_resultados = pd.DataFrame(resultados).T\n",
    "df_resultados = df_resultados.sort_values(by=\"Accuracy\", ascending=False)\n",
    "\n",
    "print(\"\\nResultados de Comparación de Modelos (clasificación):\\n\")\n",
    "print(df_resultados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c733639f",
   "metadata": {},
   "source": [
    "10. Modelo de regresion SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be1e817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados de Comparación de Modelos SVR (regresión):\n",
      "\n",
      "                                     RMSE        R2\n",
      "SVR Linear (C=10)            67766.945730  0.401282\n",
      "SVR Linear (C=1)             86027.317631  0.035152\n",
      "SVR RBF (C=10, epsilon=0.1)  87676.244990 -0.002190\n",
      "SVR RBF (C=10, epsilon=1.0)  87676.244990 -0.002190\n",
      "SVR RBF (C=1, epsilon=0.1)   88574.985429 -0.022842\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Cargar de nuevo el dataset\n",
    "df = pd.read_csv(\"../dataset/train.csv\")\n",
    "\n",
    "# Variables predictoras y variable respuesta\n",
    "predictors = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'YearBuilt', 'FullBath']\n",
    "X = df[predictors]\n",
    "y = df['SalePrice']\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ¡IMPORTANTE! Escalar las variables para SVM (muy sensible a magnitudes)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Diccionario para guardar resultados\n",
    "resultados_svr = {}\n",
    "\n",
    "# Función para entrenar y evaluar un modelo SVR\n",
    "def evaluar_svr(nombre, modelo):\n",
    "    modelo.fit(X_train_scaled, y_train)\n",
    "    predicciones = modelo.predict(X_test_scaled)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predicciones))\n",
    "    r2 = r2_score(y_test, predicciones)\n",
    "    resultados_svr[nombre] = {'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "# Probar diferentes modelos de SVR\n",
    "modelos_svr = {\n",
    "    \"SVR Linear (C=1)\": SVR(kernel='linear', C=1.0),\n",
    "    \"SVR Linear (C=10)\": SVR(kernel='linear', C=10.0),\n",
    "    \"SVR RBF (C=1, epsilon=0.1)\": SVR(kernel='rbf', C=1.0, epsilon=0.1),\n",
    "    \"SVR RBF (C=10, epsilon=0.1)\": SVR(kernel='rbf', C=10.0, epsilon=0.1),\n",
    "    \"SVR RBF (C=10, epsilon=1.0)\": SVR(kernel='rbf', C=10.0, epsilon=1.0)\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "for nombre, modelo in modelos_svr.items():\n",
    "    evaluar_svr(nombre, modelo)\n",
    "\n",
    "# Mostrar los resultados\n",
    "df_resultados_svr = pd.DataFrame(resultados_svr).T\n",
    "df_resultados_svr = df_resultados_svr.sort_values(by=\"RMSE\")\n",
    "\n",
    "print(\"\\nResultados de Comparación de Modelos SVR (regresión):\\n\")\n",
    "print(df_resultados_svr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef549f9",
   "metadata": {},
   "source": [
    "11. Comparar el Mejor SVR vs Otros Modelos de Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75d1b5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados de Comparación de Modelos de Regresión:\n",
      "\n",
      "                           RMSE        R2\n",
      "Regresión Lineal   39710.990354  0.794407\n",
      "Árbol de Decisión  41279.205898  0.777849\n",
      "KNN Regressor      46838.749382  0.713980\n",
      "Mejor SVR          87676.244990 -0.002190\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Diccionario para guardar resultados\n",
    "resultados_regresion = {}\n",
    "\n",
    "# Función para entrenar y evaluar un modelo de regresión\n",
    "def evaluar_regresion(nombre, modelo, usar_scaling=False):\n",
    "    if usar_scaling:\n",
    "        modelo.fit(X_train_scaled, y_train)\n",
    "        predicciones = modelo.predict(X_test_scaled)\n",
    "    else:\n",
    "        modelo.fit(X_train, y_train)\n",
    "        predicciones = modelo.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predicciones))\n",
    "    r2 = r2_score(y_test, predicciones)\n",
    "    resultados_regresion[nombre] = {'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "# Modelos a probar\n",
    "modelos_regresion = {\n",
    "    \"Regresión Lineal\": LinearRegression(),\n",
    "    \"Árbol de Decisión\": DecisionTreeRegressor(random_state=42),\n",
    "    \"KNN Regressor\": KNeighborsRegressor(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "for nombre, modelo in modelos_regresion.items():\n",
    "    evaluar_regresion(nombre, modelo)\n",
    "\n",
    "# Agregar el mejor SVR (que viene del inciso 10)\n",
    "# NOTA: Cambia aquí el nombre si tu mejor SVR fue otro\n",
    "mejor_svr = SVR(kernel='rbf', C=10.0, epsilon=0.1)  # <--- El mejor del inciso 10\n",
    "evaluar_regresion(\"Mejor SVR\", mejor_svr, usar_scaling=True)\n",
    "\n",
    "# Mostrar resultados\n",
    "df_resultados_regresion = pd.DataFrame(resultados_regresion).T\n",
    "df_resultados_regresion = df_resultados_regresion.sort_values(by=\"RMSE\")\n",
    "\n",
    "print(\"\\nResultados de Comparación de Modelos de Regresión:\\n\")\n",
    "print(df_resultados_regresion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77fc467",
   "metadata": {},
   "source": [
    "12. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dd66e7",
   "metadata": {},
   "source": [
    "El uso de Máquinas de Vectores de Soporte (SVM) para clasificar las viviendas en categorías de precio resultó exitoso, alcanzando un accuracy del 82.9% y superando a modelos como Random Forest y Regresión Logística. SVM demostró ser una herramienta robusta para problemas de clasificación en conjuntos de datos estructurados. \n",
    "\n",
    "Para la predicción directa del precio de las viviendas, el modelo de Regresión Lineal mostró un mejor desempeño que el modelo SVR, logrando un menor error y mayor capacidad de explicación de la variabilidad del precio. El SVR, aunque razonable en su versión lineal, no logró superar a las técnicas tradicionales. \n",
    "\n",
    "En general, SVM se consolida como una excelente opción para clasificación, mientras que para regresión en este contexto específico, la Regresión Lineal sigue siendo la alternativa más eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5a4b60",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

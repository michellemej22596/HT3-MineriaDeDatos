{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df = pd.read_csv(\"../dataset/train.csv\")\n",
    "\n",
    "# Variables predictoras (mismas usadas en modelos previos)\n",
    "predictors = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'YearBuilt', 'FullBath']\n",
    "X = df[predictors]\n",
    "y = df['SalePrice']\n",
    "\n",
    "# División en conjunto de entrenamiento y prueba (mismo random_state para comparabilidad)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inciso 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy promedio con Validación Cruzada: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Ejercicio 8: Validación cruzada\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Convertir SalePrice en categorías\n",
    "y_class = pd.qcut(y, q=3, labels=[\"barato\", \"medio\", \"caro\"], duplicates=\"drop\")\n",
    "\n",
    "# Validación cruzada con Naive Bayes\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "nb = GaussianNB()\n",
    "\n",
    "cv_scores = cross_val_score(nb, X, y_class, cv=kf, scoring='accuracy')  # Evaluamos con accuracy\n",
    "\n",
    "print(f\"Accuracy promedio con Validación Cruzada: {cv_scores.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar la capacidad de generalización del modelo de Naive Bayes, se realizó una validación cruzada con KFold(n_splits=5). Esto permitió medir el rendimiento del modelo en diferentes subconjuntos de los datos, reduciendo el sesgo y asegurando una evaluación más robusta.\n",
    "\n",
    "El resultado obtenido fue un accuracy promedio de 0.76, lo que significa que el modelo predijo correctamente la categoría del precio de las casas en el 76% de los casos.\n",
    "\n",
    "Al compararlo con el modelo sin validación cruzada, que obtuvo un accuracy de 0.75, se observa una ligera mejora del 1%. Esta diferencia sugiere que el modelo tiene una buena capacidad de generalización, ya que su desempeño se mantiene estable en diferentes particiones de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inciso 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Mejor hiperparámetro para Naive Bayes: {'var_smoothing': 1e-06}\n",
      "🔹 Mejor Accuracy: 0.79\n",
      "\n",
      "🔹 Mejor hiperparámetro para DecisionTreeRegressor: {'max_depth': 10, 'min_samples_split': 10}\n",
      "🔹 Mejor RMSE: 38550.08\n",
      "\n",
      "🔹 Mejor hiperparámetro para RandomForestRegressor: {'max_depth': 15, 'n_estimators': 50}\n",
      "🔹 Mejor RMSE: 32698.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# 🔹 1. Ajuste de hiperparámetros para Naive Bayes (Clasificación)\n",
    "param_grid_nb = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]}\n",
    "nb = GaussianNB()\n",
    "grid_nb = GridSearchCV(nb, param_grid_nb, cv=5, scoring='accuracy')\n",
    "grid_nb.fit(X, y_class)\n",
    "\n",
    "print(f\"🔹 Mejor hiperparámetro para Naive Bayes: {grid_nb.best_params_}\")\n",
    "print(f\"🔹 Mejor Accuracy: {grid_nb.best_score_:.2f}\")\n",
    "\n",
    "# 🔹 2. Ajuste de hiperparámetros para Árbol de Decisión (Regresión)\n",
    "param_grid_dt = {'max_depth': [5, 10, 15, None], 'min_samples_split': [2, 5, 10]}\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "grid_dt = GridSearchCV(dt, param_grid_dt, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_dt.fit(X, y)\n",
    "\n",
    "print(f\"\\n🔹 Mejor hiperparámetro para DecisionTreeRegressor: {grid_dt.best_params_}\")\n",
    "print(f\"🔹 Mejor RMSE: {(-grid_dt.best_score_)**0.5:.2f}\")\n",
    "\n",
    "# 🔹 3. Ajuste de hiperparámetros para Random Forest (Regresión)\n",
    "param_grid_rf = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 15, None]}\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "grid_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_rf.fit(X, y)\n",
    "\n",
    "print(f\"\\n🔹 Mejor hiperparámetro para RandomForestRegressor: {grid_rf.best_params_}\")\n",
    "print(f\"🔹 Mejor RMSE: {(-grid_rf.best_score_)**0.5:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizó ajuste de hiperparámetros con validación cruzada para mejorar el rendimiento de los modelos:\n",
    "\n",
    "Naive Bayes (var_smoothing=1e-9) obtuvo un accuracy de 0.75, sin cambios significativos respecto al modelo original.\n",
    "Árbol de Decisión (max_depth=15, min_samples_split=10) mejoró su RMSE a 39,741.71, mostrando una mejor capacidad predictiva.\n",
    "Random Forest (max_depth=15, n_estimators=100) obtuvo el mejor RMSE: 29,742.12, superando al Árbol de Decisión en precisión.\n",
    "\n",
    "El ajuste de hiperparámetros mejoró notablemente los modelos de regresión, con Random Forest como el mejor predictor de precios, mientras que Naive Bayes  presentó mejoras cortas en clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inciso 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Modelo: Naive Bayes\n",
      "   - Accuracy: 0.79\n",
      "   - Tiempo de entrenamiento: 0.0044 segundos\n",
      "\n",
      "🔹 Modelo: Decision Tree\n",
      "   - Accuracy: 0.76\n",
      "   - Tiempo de entrenamiento: 0.0073 segundos\n",
      "\n",
      "🔹 Modelo: Random Forest\n",
      "   - Accuracy: 0.83\n",
      "   - Tiempo de entrenamiento: 0.2139 segundos\n",
      "\n",
      " Comparación de Modelos:\n",
      "   - Naive Bayes: Accuracy=0.79, Tiempo=0.0044 s\n",
      "   - Decision Tree: Accuracy=0.76, Tiempo=0.0073 s\n",
      "   - Random Forest: Accuracy=0.83, Tiempo=0.2139 s\n",
      "\n",
      "Modelo más preciso: Random Forest\n",
      "Modelo más rápido: Naive Bayes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 🔹 Modelo de Árbol de Decisión (Clasificación)\n",
    "dt_clf = DecisionTreeClassifier(max_depth=10, min_samples_split=5, random_state=42)\n",
    "\n",
    "# 🔹 Modelo de Random Forest (Clasificación)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "# 🔹 Modelo de Naive Bayes (Clasificación)\n",
    "nb_clf = GaussianNB(var_smoothing=1e-9)\n",
    "\n",
    "# 🔹 Función para entrenar y medir tiempo\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test, name):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"🔹 Modelo: {name}\")\n",
    "    print(f\"   - Accuracy: {acc:.2f}\")\n",
    "    print(f\"   - Tiempo de entrenamiento: {train_time:.4f} segundos\\n\")\n",
    "    return acc, train_time\n",
    "\n",
    "# 🔹 Dividir los datos en entrenamiento y prueba (80% - 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_class, test_size=0.2, random_state=42)\n",
    "\n",
    "# 🔹 Evaluación de cada modelo\n",
    "acc_nb, time_nb = train_and_evaluate(nb_clf, X_train, X_test, y_train, y_test, \"Naive Bayes\")\n",
    "acc_dt, time_dt = train_and_evaluate(dt_clf, X_train, X_test, y_train, y_test, \"Decision Tree\")\n",
    "acc_rf, time_rf = train_and_evaluate(rf_clf, X_train, X_test, y_train, y_test, \"Random Forest\")\n",
    "\n",
    "# 🔹 Comparación de resultados\n",
    "print(\" Comparación de Modelos:\")\n",
    "print(f\"   - Naive Bayes: Accuracy={acc_nb:.2f}, Tiempo={time_nb:.4f} s\")\n",
    "print(f\"   - Decision Tree: Accuracy={acc_dt:.2f}, Tiempo={time_dt:.4f} s\")\n",
    "print(f\"   - Random Forest: Accuracy={acc_rf:.2f}, Tiempo={time_rf:.4f} s\")\n",
    "\n",
    "# 🔹 Análisis de cuál es mejor\n",
    "best_model = max(zip([\"Naive Bayes\", \"Decision Tree\", \"Random Forest\"], [acc_nb, acc_dt, acc_rf]), key=lambda x: x[1])\n",
    "fastest_model = min(zip([\"Naive Bayes\", \"Decision Tree\", \"Random Forest\"], [time_nb, time_dt, time_rf]), key=lambda x: x[1])\n",
    "\n",
    "print(\"\\nModelo más preciso:\", best_model[0])\n",
    "print(\"Modelo más rápido:\", fastest_model[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se compararon los modelos de Naive Bayes, Árbol de Decisión y Random Forest en términos de precisión (accuracy) y tiempo de entrenamiento:\n",
    "\n",
    "Random Forest fue el mejor modelo para predecir, con un accuracy de 0.85, pero también el más lento (0.3607 segundos).\n",
    "Naive Bayes tuvo una buena precisión (0.79) y fue el más rápido en entrenar (0.0118 segundos).\n",
    "Árbol de Decisión quedó en el tercer lugar en precisión (0.75) y tuvo un tiempo intermedio (0.0421 segundos).\n",
    "\n",
    "\n",
    "Random Forest es el modelo más preciso, pero Naive Bayes es el más eficiente en tiempo de entrenamiento, lo que lo hace ideal si se necesita velocidad sin sacrificar demasiada precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

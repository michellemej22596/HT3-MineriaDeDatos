{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Haga un modelo usando validación cruzada, compare los resultados de este con los del\n",
    "modelo anterior. ¿Cuál funcionó mejor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE del modelo KNN sin validación cruzada: 48941.00\n",
      "RMSE con validación cruzada (10 folds): 45263.53\n",
      "Desviación estándar del RMSE con validación cruzada: 6684.58\n",
      "\n",
      "Comparación de RMSE:\n",
      "Modelo sin validación cruzada: 48941.00\n",
      "Modelo con validación cruzada: 45263.53\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Cargar los datos limpios\n",
    "df_cleaned = pd.read_csv(\"../dataset/train_cleaned.csv\")\n",
    "\n",
    "# Separar características (X) y variable objetivo (y)\n",
    "X_cleaned = df_cleaned.drop(columns=['SalePrice'])\n",
    "y_cleaned = df_cleaned['SalePrice']\n",
    "\n",
    "# Identificar columnas categóricas\n",
    "categorical_columns = X_cleaned.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Convertir variables categóricas en variables numéricas con one-hot encoding\n",
    "X_cleaned_encoded = pd.get_dummies(X_cleaned, columns=categorical_columns)\n",
    "\n",
    "# División en conjunto de entrenamiento y prueba (80%-20%)\n",
    "X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(\n",
    "    X_cleaned_encoded, y_cleaned, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir y entrenar el modelo KNN\n",
    "knn_cleaned = KNeighborsRegressor(n_neighbors=5, metric='minkowski')\n",
    "knn_cleaned.fit(X_train_cleaned, y_train_cleaned)\n",
    "\n",
    "# Predicción en el conjunto de prueba\n",
    "y_pred_cleaned = knn_cleaned.predict(X_test_cleaned)\n",
    "\n",
    "# Calcular RMSE sin validación cruzada\n",
    "rmse_knn_cleaned = np.sqrt(mean_squared_error(y_test_cleaned, y_pred_cleaned))\n",
    "print(f\"RMSE del modelo KNN sin validación cruzada: {rmse_knn_cleaned:.2f}\")\n",
    "\n",
    "# Aplicar validación cruzada con 10 folds\n",
    "kf_cleaned = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores_cleaned = cross_val_score(knn_cleaned, X_cleaned_encoded, y_cleaned, scoring='neg_root_mean_squared_error', cv=kf_cleaned)\n",
    "\n",
    "# Calcular RMSE promedio con validación cruzada\n",
    "rmse_mean_cleaned = -cv_scores_cleaned.mean()\n",
    "rmse_std_cleaned = cv_scores_cleaned.std()\n",
    "\n",
    "print(f\"RMSE con validación cruzada (10 folds): {rmse_mean_cleaned:.2f}\")\n",
    "print(f\"Desviación estándar del RMSE con validación cruzada: {rmse_std_cleaned:.2f}\")\n",
    "\n",
    "# Comparación de modelos\n",
    "print(\"\\nComparación de RMSE:\")\n",
    "print(f\"Modelo sin validación cruzada: {rmse_knn_cleaned:.2f}\")\n",
    "print(f\"Modelo con validación cruzada: {rmse_mean_cleaned:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo KNN con validación cruzada de 10 folds obtuvo un **RMSE de 45,263.53**, mientras que el modelo sin validación cruzada tuvo un **RMSE de 48,941.00**, indicando que la validación cruzada mejoró la precisión del modelo al reducir el error en aproximadamente **3,677.47 unidades**. Además, la **desviación estándar del RMSE (6,684.58)** sugiere que el rendimiento del modelo es relativamente estable en los distintos conjuntos de validación. Estos resultados demuestran que la validación cruzada ayuda a mejorar la generalización del modelo, evitando el sobreajuste y proporcionando predicciones más confiables en datos nuevos. Para futuras mejoras, se podría optimizar los hiperparámetros de KNN o probar modelos más complejos como **Random Forest** o **Gradient Boosting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Tanto para los modelos de regresión como de clasificación, pruebe con varios valores de los\n",
    "hiperparámetros ¿Qué parámetros pueden tunearse en un KNN?, use el mejor modelo del\n",
    "tuneo, ¿Mejoraron los resultados usando el mejor modelo ahora? Explique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "Mejor RMSE con validación cruzada: 41572.45\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Cargar los datos limpios\n",
    "df_cleaned = pd.read_csv(\"../dataset/train_cleaned.csv\")\n",
    "\n",
    "# Separar características (X) y variable objetivo (y)\n",
    "X_cleaned = df_cleaned.drop(columns=['SalePrice'])\n",
    "y_cleaned = df_cleaned['SalePrice']\n",
    "\n",
    "# Identificar columnas categóricas\n",
    "categorical_columns = X_cleaned.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Convertir variables categóricas en variables numéricas con one-hot encoding\n",
    "X_cleaned_encoded = pd.get_dummies(X_cleaned, columns=categorical_columns)\n",
    "\n",
    "# División en conjunto de entrenamiento y prueba (80%-20%)\n",
    "X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(\n",
    "    X_cleaned_encoded, y_cleaned, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir el espacio de búsqueda de hiperparámetros\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "# Definir el modelo KNN\n",
    "knn_tuned = KNeighborsRegressor()\n",
    "\n",
    "# Realizar búsqueda de hiperparámetros con validación cruzada (10 folds)\n",
    "grid_search = GridSearchCV(knn_tuned, param_grid, scoring='neg_root_mean_squared_error', cv=10, n_jobs=-1)\n",
    "grid_search.fit(X_train_cleaned, y_train_cleaned)\n",
    "\n",
    "# Obtener los mejores hiperparámetros y el mejor resultado\n",
    "best_params = grid_search.best_params_\n",
    "best_rmse = -grid_search.best_score_\n",
    "\n",
    "print(f\"Mejores hiperparámetros: {best_params}\")\n",
    "print(f\"Mejor RMSE con validación cruzada: {best_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de ajustar los hiperparámetros del modelo KNN, se logró una mejora significativa en el rendimiento. El mejor modelo encontrado utiliza la métrica de distancia **Manhattan**, un número óptimo de **9 vecinos (`k=9`)**, y un esquema de ponderación basado en la distancia en lugar de pesos uniformes. Estos cambios redujeron el **RMSE de 45,263.53 a 41,572.45**, lo que representa una mejora del **8.1%** en la precisión del modelo. El uso de la distancia Manhattan permitió capturar mejor las relaciones en los datos, mientras que aumentar el número de vecinos suavizó las predicciones y redujo la sensibilidad al ruido. Además, ponderar los vecinos por distancia otorgó mayor peso a los más cercanos, generando estimaciones más precisas. Estos resultados demuestran que la **optimización de hiperparámetros es clave para mejorar la generalización del modelo**, haciendo que las predicciones sean más confiables y precisas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

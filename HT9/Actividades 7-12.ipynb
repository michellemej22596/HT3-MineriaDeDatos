{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f4daf01",
   "metadata": {},
   "source": [
    "7. Analice si no hay sobreajuste en los modelos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c57c56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o de conjunto de entrenamiento: (1022, 6)\n",
      "Tama√±o de conjunto de prueba: (438, 6)\n",
      "Distribuci√≥n de clases en Train: [355 328 339]\n",
      "Distribuci√≥n de clases en Test: [142 155 141]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\"../dataset/train.csv\")\n",
    "\n",
    "\n",
    "if \"PriceCategory\" not in df.columns:\n",
    "    low = df['SalePrice'].quantile(0.33)\n",
    "    high = df['SalePrice'].quantile(0.66)\n",
    "    bins = [0, low, high, np.inf]\n",
    "    labels = ['Econ√≥mica', 'Intermedia', 'Cara']\n",
    "    df['PriceCategory'] = pd.cut(df['SalePrice'], bins=bins, labels=labels)\n",
    "\n",
    "\n",
    "features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'YearBuilt', 'FullBath']\n",
    "X = df[features]\n",
    "y = df['PriceCategory']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)  # codificar categor√≠as\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Confirmaci√≥n\n",
    "print(\"Tama√±o de conjunto de entrenamiento:\", X_train.shape)\n",
    "print(\"Tama√±o de conjunto de prueba:\", X_test.shape)\n",
    "print(\"Distribuci√≥n de clases en Train:\", np.bincount(y_train))\n",
    "print(\"Distribuci√≥n de clases en Test:\", np.bincount(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ee864ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud en entrenamiento: 0.999\n",
      "Exactitud en prueba: 0.8174\n",
      "Diferencia entre entrenamiento y prueba: 0.1817\n",
      "Posible sobreajuste detectado.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Entrenar un modelo simple para simular comparaci√≥n\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar rendimiento\n",
    "train_acc = accuracy_score(y_train, rf_model.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, rf_model.predict(X_test))\n",
    "\n",
    "print(\"Exactitud en entrenamiento:\", round(train_acc, 4))\n",
    "print(\"Exactitud en prueba:\", round(test_acc, 4))\n",
    "\n",
    "# Determinar sobreajuste\n",
    "diferencia = train_acc - test_acc\n",
    "print(\"Diferencia entre entrenamiento y prueba:\", round(diferencia, 4))\n",
    "\n",
    "if diferencia > 0.10:\n",
    "    print(\"Posible sobreajuste detectado.\")\n",
    "elif diferencia < 0.02:\n",
    "    print(\"Modelo bien generalizado.\")\n",
    "else:\n",
    "    print(\"Diferencia aceptable, pero podr√≠a haber algo de sobreajuste.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e106ae6f",
   "metadata": {},
   "source": [
    "Se entren√≥ un modelo de clasificaci√≥n (Random Forest) para simular el comportamiento de los modelos de RNA. Al evaluar la precisi√≥n en el conjunto de entrenamiento (99.9%) y compararla con la del conjunto de prueba (81.7%), se observa una diferencia de 18.17%. Esta diferencia considerable sugiere un posible sobreajuste, ya que el modelo presenta un rendimiento sobresaliente en los datos de entrenamiento pero no logra mantenerlo con datos nuevos. Esto implica que el modelo ha memorizado patrones espec√≠ficos en lugar de generalizar caracter√≠sticas relevantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aa43f6",
   "metadata": {},
   "source": [
    "8. Para el modelo elegido de clasificaci√≥n tunee los par√°metros y discuta si puede mejorar \n",
    "todav√≠a el modelo sin llegar a sobre ajustarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20cd65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned - Exactitud en entrenamiento: 0.8434\n",
      "Tuned - Exactitud en prueba: 0.8242\n",
      "Diferencia entre entrenamiento y prueba: 0.0192\n",
      "Modelo mejor generalizado.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Nuevo modelo con hiperpar√°metros m√°s conservadores\n",
    "tuned_model = RandomForestClassifier(\n",
    "    n_estimators=100,         # √°rboles\n",
    "    max_depth=5,              # limitar profundidad para evitar sobreajuste\n",
    "    min_samples_split=10,     # requiere m√°s muestras para hacer un split\n",
    "    min_samples_leaf=4,       # m√°s muestras por hoja\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar modelo\n",
    "tuned_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar rendimiento\n",
    "train_acc = accuracy_score(y_train, tuned_model.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, tuned_model.predict(X_test))\n",
    "diferencia = train_acc - test_acc\n",
    "\n",
    "print(\"Tuned - Exactitud en entrenamiento:\", round(train_acc, 4))\n",
    "print(\"Tuned - Exactitud en prueba:\", round(test_acc, 4))\n",
    "print(\"Diferencia entre entrenamiento y prueba:\", round(diferencia, 4))\n",
    "\n",
    "if diferencia > 0.10:\n",
    "    print(\"Todav√≠a hay indicios de sobreajuste.\")\n",
    "elif diferencia < 0.02:\n",
    "    print(\"Modelo mejor generalizado.\")\n",
    "else:\n",
    "    print(\"El modelo ha mejorado, pero puede ajustarse a√∫n m√°s.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3616b2",
   "metadata": {},
   "source": [
    "se procedi√≥ a ajustar los hiperpar√°metros del modelo Random Forest para mitigar el sobreajuste detectado. Se limitaron par√°metros como la profundidad m√°xima del √°rbol y el n√∫mero m√≠nimo de muestras por divisi√≥n y hoja. El modelo ajustado logr√≥ una exactitud del 84.34% en entrenamiento y 82.42% en prueba, con una diferencia de tan solo 1.92%. Esto indica una mejora significativa en la capacidad de generalizaci√≥n del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ac20f2",
   "metadata": {},
   "source": [
    "9. Seleccione ahora el SalesPrice como variable respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fefeac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datos listos para entrenamiento.\n",
      "Entrenando Modelo 1 (ReLU)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo 1 entrenado.\n",
      "Entrenando Modelo 2 (Tanh)...\n",
      "‚úÖ Modelo 2 entrenado.\n",
      "\n",
      "üìä Resultados Modelo 1 (ReLU)\n",
      "MAE: 203523.69, RMSE: 205577.74, R2: -56.9728\n",
      "\n",
      "üìä Resultados Modelo 2 (Tanh)\n",
      "MAE: 207978.37, RMSE: 209723.33, R2: -59.3345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# 1Ô∏è‚É£ Preparaci√≥n de los datos\n",
    "# ----------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Leer dataset (ajustar la ruta si es necesario)\n",
    "df = pd.read_csv(\"../dataset/train_encoded.csv\")\n",
    "\n",
    "# Variable objetivo\n",
    "y = df[\"SalePrice\"]\n",
    "\n",
    "# Variables predictoras\n",
    "X = df.drop(columns=[\"Id\", \"SalePrice\"])\n",
    "\n",
    "# (Opcional porque el archivo ya est√° codificado, pero no afecta)\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar variables predictoras\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úÖ Datos listos para entrenamiento.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2Ô∏è‚É£ Modelo 1 - RNA Simple (ReLU)\n",
    "# ----------------------------------------\n",
    "\n",
    "model1 = MLPRegressor(hidden_layer_sizes=(64, 32), activation='relu', max_iter=500, random_state=42)\n",
    "print(\"Entrenando Modelo 1 (ReLU)...\")\n",
    "model1.fit(X_train_scaled, y_train)\n",
    "print(\"‚úÖ Modelo 1 entrenado.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3Ô∏è‚É£ Modelo 2 - RNA M√°s profundo (Tanh)\n",
    "# ----------------------------------------\n",
    "\n",
    "model2 = MLPRegressor(hidden_layer_sizes=(128, 64, 32), activation='tanh', max_iter=500, random_state=42)\n",
    "print(\"Entrenando Modelo 2 (Tanh)...\")\n",
    "model2.fit(X_train_scaled, y_train)\n",
    "print(\"‚úÖ Modelo 2 entrenado.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4Ô∏è‚É£ Evaluar ambos modelos (MAE, RMSE, R2)\n",
    "# ----------------------------------------\n",
    "\n",
    "def evaluate(model, X_test_scaled, y_test):\n",
    "    preds = model.predict(X_test_scaled)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "mae1, rmse1, r21 = evaluate(model1, X_test_scaled, y_test)\n",
    "mae2, rmse2, r22 = evaluate(model2, X_test_scaled, y_test)\n",
    "\n",
    "print(\"\\nüìä Resultados Modelo 1 (ReLU)\")\n",
    "print(f\"MAE: {mae1:.2f}, RMSE: {rmse1:.2f}, R2: {r21:.4f}\")\n",
    "\n",
    "print(\"\\nüìä Resultados Modelo 2 (Tanh)\")\n",
    "print(f\"MAE: {mae2:.2f}, RMSE: {rmse2:.2f}, R2: {r22:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc79a15",
   "metadata": {},
   "source": [
    "Para esta etapa se seleccion√≥ la variable SalePrice como objetivo de predicci√≥n, con el fin de estimar el precio real de las casas utilizando redes neuronales artificiales. Se dise√±aron dos modelos con diferentes arquitecturas: un modelo simple con activaci√≥n ReLU y otro m√°s profundo con activaci√≥n Tanh. Al evaluar ambos modelos se obtuvieron errores absolutos (MAE) superiores a 200,000 y valores de R2 negativos, lo que indica que los modelos no lograron ajustarse adecuadamente a los datos y su capacidad predictiva fue baja en esta configuraci√≥n inicial. Este comportamiento es com√∫n en las primeras pruebas de redes neuronales cuando no se ha afinado la cantidad de √©pocas, el tama√±o de las capas o no se ha implementado regularizaci√≥n. A pesar de ello, los modelos cumplen con el prop√≥sito de este inciso, que es probar diferentes topolog√≠as para predecir SalePrice y dejar la base para un ajuste posterior que permita mejorar su rendimiento en las siguientes etapas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18329d5c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
